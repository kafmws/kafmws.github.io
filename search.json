[{"title":"LLM 结构化输出原理、实现方式及实践","url":"/notes/LLM/LLM%20%E7%BB%93%E6%9E%84%E5%8C%96%E8%BE%93%E5%87%BA%E5%8E%9F%E7%90%86%E3%80%81%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E5%8F%8A%E5%AE%9E%E8%B7%B5/","content":" 结构化输出的意义\nLLM 是输出不可控的概率模型，而结构化输出则增强输出的可控性。\n有了这种可控性，LLM 就具备了一个程序的交互 interface 可以稳定地接入上下游程序，比如调用工具\n 结构化输出的原理及实现方式\n实现格式化输出通常有以下几种手段，\n\n提示词工程\n通过指令 “只输出JSON”，few-shot 示例等提示词技巧引导模型进行格式化输出\n后处理\ninstruct 等库对模型输出进行后处理，进行提取或修复等。包括解析后反馈错误重新生成等。\n约束解码\n在选择 token 时用 mask 机制直接排除不符合输出格式的候选 token，在有限输出空间内选择 token。\n{&quot;key&quot;: value}，从仅让模型预测格式串中的value部分，到约束value的格式/类型，约束解码都可以保证可靠的格式化输出。\n再进一步，通过等价的状态机进行约束解码，可以进行任意的格式化输出。约束解码是结构化输出的主要工程手段。\nSFT / RL\n通过后训练手段形成输出偏好，使模型遵循一定模式。可靠性高，是结构化输出的理论保障、能力来源。\n\n当前许多模型厂商从 SFT/RL 的角度增强模型的格式化输出能力，并从推理端实现约束解码（例如Ollama），从而提供可靠的结构化输出 API。\n 工具调用与结构化输出，先有鸡还是先有蛋\n依靠结构化输出的结果，我们才能稳定地处理工具调用\n然而，如果模型能调用给定的工具，那么任意输出格式都可以包装成工具，通过 LLM 填写调用参数，也就实现了指定格式的输出\n看起来两者相互成就，已经变成了鸡生蛋，蛋生鸡的问题\n许多厂商都强调模型有 tool use/ function call 能力，却不强调模型支持结构化输出，可能相比于输出“特定”格式，输出函数参数更好构造训练数据以及验证吧\n 本地模型在 langchain 中的结构化输出\n本文在 langchain 以下生态中进行讨论（2026-02-02）\nlangchain-core            1.2.7langchain-openai          1.1.7langchain-ollama          1.0.1\n以 YesNoJudge 类的 JSON 格式，搭配不同 with_structured_output() 的格式化输出方式（即method参数）测试结构化输出表现\nmethod 参数可选项有 json_schema, function_calling 和 json_mode，其中json_mode因无法给出确定格式的 JSON ，需要后处理，不推荐使用。（来源：https://platform.openai.com/docs/guides/structured-outputs#json-mode）\nclass YesNoJudge(BaseModel):    &quot;&quot;&quot;return judge result from the context with this function.&quot;&quot;&quot;    yes_or_no: Literal[&quot;yes&quot;, &quot;no&quot;] = Field(        description=&quot;The answer should be either &#x27;yes&#x27; or &#x27;no&#x27;&quot;    )    explanation: strjudge = ChatOpenAI(            model=model_name, temperature=0.6, streaming=True, **fast_judge_config        )        judge = judge.with_structured_output(            schema=YesNoJudge, method=&quot;function_calling&quot;, strict=True, include_raw=True        )\n\n图：指定`json_schema` 方式，在 prompt 中提示按JSON格式输出后，gpt-oss:20b 仍调用不存在的工具进行格式化输出\n\n图：指定 `function_calling` 方式，在 prompt 中提示按JSON格式输出后，qwen3:4b 会在内容中输出 json，不调用工具\n\n图：指定 `function_calling` 方式，去除json prompt，qwen3:4b 仍倾向于遵循指令在内容中输出结果，不调用工具\n\n图：指定 `function_calling` 方式，去除指令式prompt，qwen3:4b 有概率调用工具返回结果\n可见 Qwen 模型更重视指令遵循，而 GPT 偏向于使用工具\n langchain 中 with_structured_output() 的实现简析\n不同 backend 生态包的 with_structured_output() 实现不同，\n对于langchan-openai：\n\nfunction_calling 把 JSON schema 作为 tool 传入，并填充 tool_choice 参数，强制 LLM 使用工具输出工具调用的 schema\n相当于把工具调用能力转化为结构化输出能力\njson_schema 方式则是对输出内容进行解析，该参数\njson_mode 建议配合 prompt 使用，全靠模型发挥\n而 create_agnet API 中 response_format 也是直接调用 LLM 后端的结构化输出能力\n\n langchain + langchain-openai + Ollama 后端结构化输出踩的坑\n为什么用 langchain-openai 不用 langchain-ollama，因为想着兼容 OpenAI API 会好一些\n甚至用 langchain-ollama + Ollama 还一直出现 502 报错。。openai / curl 均正常\n\n\n看似兼容，实则不兼容\n如 langchain[openai, ollama] 中 chat_models 的 with_structured_output() 实现不一致\n且将 Ollama 作为后端使用 langchain-openai 时 with_structured_output 的表现和模型高度相关，需根据模型调优 method 参数\n实际支持多个后端仍需要进行适配\n\n\n多处实现，效果不一\n如 langchain[openai, ollama] 中 chat_models 的 with_structured_output() 与 from langchain.agents import create_agent 的 response_format 都用于结构化输出\n然而可靠性不同\n\n\n过度封装\n源码里到处是消除警告的类型不匹配 # type: ignore\nMessageState 的消息 messages 传入 AgentState 的 messages 提示类型不匹配，有点搞笑\n\n\n","categories":["notes"],"tags":["LLM杂七杂八"]},{"title":"龙潭公园里的鹅和鸭们日子过得无忧无虑","url":"/fragments/Fragments/%E9%BE%99%E6%BD%AD%E5%85%AC%E5%9B%AD%E9%87%8C%EF%BC%8C%E9%B9%85%E5%92%8C%E9%B8%AD%E4%BB%AC%E6%97%A5%E5%AD%90%E8%BF%87%E5%BE%97%E6%97%A0%E5%BF%A7%E6%97%A0%E8%99%91/","content":"龙潭公园里的鹅和鸭们日子过得无忧无虑呐。\n潭水表面大都结着冰，沿潭水绕行一圈，每个鹅鸭聚集的岸边都有人在喂食，有馒头，有不知名的食儿，甚至还有个眼镜哥带一大串葡萄来喂。\n馒头屑浮在水面上，鸭子悠悠游来伸脖一衔便进肚，而葡萄都沉入水中。\n有鸭子站在冰面上了，就有葡萄滚落周围，这下总能吃了吧！\n可葡萄圆滚滚的，这黑绿头的鸭子用窄窄扁扁的嘴衔几次掉落几次，只有极少数葡萄完成了使命。\n眼镜哥毫不在乎，在冰上、在水里，吃不吃、吃不吃得着无关紧要，喂食本是一种过程。\n继续往前走，又一大群鸭，和拎一大袋馒头的大姨。这边鸭也是游水时偷闲吃两口，但成群结队游向岸边还是给足了大姨面子。\n有旁人说道，一清早就有人喂过了！\n怨不得鸭吃得糊弄，原来是尝个咸淡，看合不合胃口。\n龙潭公园里，鹅和鸭们日子过得无忧无虑呐。\n25年12月21日\n","categories":["fragments"],"tags":["随笔"]}]